{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial import distance\n",
    "from scipy.stats import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(files[1],delimiter=\"::\").to_numpy()\n",
    "trX,tX,trY,tY = train_test_split(data[:,:2],data[:,2])\n",
    "users = np.max(data[:,0])\n",
    "items = np.max(data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.zeros((users,items))\n",
    "for i in range(len(trX)):\n",
    "    dataset[(trX[i,0])-1,(trX[i,1])-1] = trY[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pip:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.r_max = np.max(data)\n",
    "        self.r_min = np.min(data)\n",
    "        self.r_range = self.r_max - self.r_min\n",
    "        self.r_med = (self.r_max+self.r_min)/2\n",
    "        self.agg = np.vectorize(self.agreement)\n",
    "        self.r_avg_items = np.mean(data,axis=0)\n",
    "        self.dist = np.vectorize(self.distance)\n",
    "        self.prox = np.vectorize(self.proximity)\n",
    "        self.pop = np.vectorize(self.popularity)\n",
    "        self.im = np.vectorize(self.impact)\n",
    "    def agreement(self,r1,r2):#to calculate the agreement between the two ratings \n",
    "        if (r1>self.r_med and r2>self.r_med) or (r1<self.r_med and r2<self.r_med):\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "    def distance(self,r1,r2,k): # to find the absolute difference in two ratings\n",
    "        if k:\n",
    "            return abs(r1-r2)\n",
    "        return abs(2*(r1-r2))\n",
    "    def proximity(self,r1,r2,d,k):\n",
    "        return( 2*(self.r_range)+1)-d**2\n",
    "    def impact(self,r1,r2,k): #how strong the affinity is of the user towards the item\n",
    "        if k:\n",
    "            return (abs(r1-self.r_med)+1)*(abs(r2-self.r_med)+1)\n",
    "        return 1/ ((abs(r1-self.r_med)+1)*(abs(r2-self.r_med)+1))\n",
    "    def popularity(self,r1,r2,r_avg_i,k):\n",
    "        if k :\n",
    "            return 1 + (((r1+r2)/2)-r_avg_i)**2\n",
    "        return 1\n",
    "    def PIP(self,u1,u2):\n",
    "        k = self.agg(u1,u2)\n",
    "        d = self.dist(u1,u2,k)\n",
    "        px = self.prox(u1,u2,d,k)\n",
    "        i = self.im(u1,u2,k)\n",
    "        pp = self.pop(u1,u2,self.r_avg_items,k)\n",
    "        return np.sum(px*i*pp)\n",
    "    def simi(self):\n",
    "        users = self.data.shape[0]\n",
    "        self.sim = np.zeros((users,users))\n",
    "        for i in range(users):\n",
    "            for j in range(i,users):\n",
    "                self.sim[i,j] = self.PIP(self.data[i,:],self.data[j,:])\n",
    "                self.sim[j,i] = self.sim[i,j]\n",
    "        return self.sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mpip:\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        self.median = np.median(data)\n",
    "        self.rmax = np.max(data)\n",
    "        self.rmin = np.min(data)\n",
    "        self.med_p = np.median(np.append(data[data>self.median],data[data>self.median]))\n",
    "        self.med_m = np.median(np.append(data[data<self.median],data[data<self.median]))\n",
    "        self.r_avg_items = np.mean(data,axis=0)\n",
    "        self.dist = np.vectorize(self.distance)\n",
    "        self.prox = np.vectorize(self.proximity)\n",
    "        self.pop = np.vectorize(self.popularity)\n",
    "        self.im = np.vectorize(self.impact)\n",
    "        self.agg = np.vectorize(self.agreement)\n",
    "        self.r_med = (self.rmax+self.rmin)/2\n",
    "    def agreement(self,r1,r2):\n",
    "        if (r1>self.r_med and r2>self.r_med) or (r1<self.r_med and r2<self.r_med):\n",
    "            return 1\n",
    "        else :\n",
    "            return 0\n",
    "    def distance(self,r1,r2):\n",
    "        return abs(r1-r2)\n",
    "    def proximity(self,k,d):\n",
    "        if k:\n",
    "            return ((d - ((self.med_m+self.med_p)/2))/(self.rmax-self.rmin))**2\n",
    "        elif d>self.median:\n",
    "            return 0.75 * (((1/d)/(self.rmax-self.rmin))**2)\n",
    "        elif d ==self.median:\n",
    "            return 0.5 * (((1/d)/(self.rmax-self.rmin))**2)\n",
    "        return 0.25 * (((1/d)/(self.rmax-self.rmin))**2)\n",
    "    def impact(self,r1,r2,k):\n",
    "        if k:\n",
    "            return math.e**-(1/ ((abs(r1-self.r_med)+1)*(abs(r2-self.r_med)+1)))\n",
    "        return 1/ ((abs(r1-self.r_med)+1)*(abs(r2-self.r_med)+1))\n",
    "    def popularity(self,r1,r2,k,rI):\n",
    "        if k:\n",
    "            return math.log10(2+(((r1+r2)/2)-rI)**2)\n",
    "        return 0.3010\n",
    "    def MPIP(self,u1,u2):\n",
    "        k = self.agg(u1,u2)\n",
    "        d = self.dist(u1,u2)\n",
    "        px = self.prox(k,d)\n",
    "        i = self.im(u1,u2,k)\n",
    "        pp = self.pop(u1,u2,k,self.r_avg_items)\n",
    "        return np.sum(px*i*pp)\n",
    "    def simi(self):\n",
    "        users = self.data.shape[0]\n",
    "        print(users)\n",
    "        self.sim = np.zeros((users,users))\n",
    "        for i in range(users):\n",
    "            for j in range(i,users):\n",
    "                self.sim[i,j] = self.MPIP(self.data[i],self.data[j])\n",
    "                self.sim[j,i] = self.sim[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cosine:\n",
    "    def __init__(self,data):\n",
    "        self.sim = 1- pairwise_distances(data,metric=\"cosine\")\n",
    "class Jaccard:\n",
    "    def __init__(self,data):\n",
    "        self.sim = np.zeros([data.shape[0],data.shape[0]])\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(i,data.shape[0]):\n",
    "                self.sim[i,j] = distance.jaccard(data[i],data[j])\n",
    "                self.sim[j,i] = self.sim[i,j]\n",
    "class pearson:\n",
    "    def __init__(self,data):\n",
    "        self.sim = np.zeros([data.shape[0],data.shape[0]])\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(i,data.shape[0]):\n",
    "                r,p = stats.pearsonr(i,j)\n",
    "                self.sim[i,j] = r\n",
    "                self.sim[j,i] = self.sim[i,j]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rating_pred:\n",
    "    def __init__(self,\n",
    "                    matrix,\n",
    "                    test,\n",
    "                    pip = 0,\n",
    "                    mpip = 0,\n",
    "                    cosine = 0,\n",
    "                    jaccard = 0,\n",
    "                    pearson = 0\n",
    "                    ):\n",
    "        self.test = test\n",
    "        self.matrix = matrix\n",
    "        self.items = matrix.shape[1]\n",
    "        self.pip = pip\n",
    "        self.mpip = mpip\n",
    "        self.cosine = cosine \n",
    "        self.jaccard = jaccard\n",
    "        self.pearson = pearson\n",
    "        self.pip_pred = []\n",
    "        self.mpip_pred = []\n",
    "        self.jaccard_pred = []\n",
    "        self.pearson_pred = []\n",
    "        \n",
    "    def PredRating(self,user,item,similarity):\n",
    "        try:\n",
    "            top = similarity[user].argsort()[1:100]\n",
    "        except IndexError:\n",
    "            sum,count = 0,0\n",
    "            for j in range(self.items):\n",
    "                if self.matrix[user,j] != 0:\n",
    "                    count+=1\n",
    "                    sum+=1\n",
    "            return sum/count\n",
    "        temp,avgUh,simi = [],[],[]\n",
    "        for i in top:\n",
    "            if self.matrix[i,item] !=0:\n",
    "                temp.append(i)\n",
    "                simi.append(similarity[user,i])\n",
    "        temp.append(user)\n",
    "        for i in temp:\n",
    "            sum,count = 0,0\n",
    "            for j in range(self.items):\n",
    "                if self.matrix[i,j] != 0:\n",
    "                    count+=1\n",
    "                    sum+=self.matrix[i,j]\n",
    "            avgUh.append(sum/count)\n",
    "        avgU = np.nan_to_num(np.array(avgUh.pop()))\n",
    "        temp.pop()\n",
    "        if len(temp)==0:\n",
    "            return avgU\n",
    "        simi = np.nan_to_num(np.array(simi))\n",
    "        num = (simi*(avgUh-avgU)).sum()\n",
    "        den = simi.sum()\n",
    "        # for i in range(len(temp)):\n",
    "        #     num+=similarity[user,temp[i]]*avgUh[i]\n",
    "        #     den+=similarity[user,temp[i]]\n",
    "        try:\n",
    "            result = (round((avgU+num/den),0))\n",
    "        except ZeroDivisionError:\n",
    "            result = 0\n",
    "        return result\n",
    "    def co(self):\n",
    "        l = []\n",
    "        for user in self.test:\n",
    "            l.append(self.PredRating(int(user[0])-1,int(user[1])-1,self.cosine))\n",
    "        self.cosine_pred = np.array(l)\n",
    "    def ja(self):\n",
    "        l = []\n",
    "        for user in self.test:\n",
    "            l.append(self.PredRating(int(user[0])-1,int(user[1])-1,self.jaccard))\n",
    "        self.jaccard_pred = np.array(l)\n",
    "    def pe(self):\n",
    "        l = []\n",
    "        for user in self.test:\n",
    "            l.append(self.PredRating(int(user[0])-1,int(user[1])-1,self.pearson))\n",
    "        self.pearson_pred = np.array(l)\n",
    "    def p(self):\n",
    "        l = []\n",
    "        for user in self.test:\n",
    "            l.append(self.PredRating(int(user[0])-1,int(user[1])-1,self.pip))\n",
    "        self.pip_pred = np.array(l)      \n",
    "    def mp(self):\n",
    "        l = []\n",
    "        for user in self.test:\n",
    "            l.append(self.PredRating(int(user[0])-1,int(user[1])-1,self.mpip))\n",
    "        self.mpip_pred = np.array(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = np.concatenate((tX,np.array([tY]).T),axis=1)\n",
    "pip_obj = (pip(dataset))\n",
    "pip_obj.simi()\n",
    "pd.DataFrame(pip_obj.sim).to_csv(\"pip.csv\",sep=\",\",index=False)\n",
    "pred_obj = rating_pred(dataset,test_dataset,pip_obj.sim)\n",
    "pred_obj.p()\n",
    "pd.DataFrame(pred_obj.pip_pred).to_csv(\"../../results/ml-100k/pip.csv\")\n",
    "pip_obj = None\n",
    "pred_obj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpip_obj = (mpip(dataset))\n",
    "mpip_obj.simi()\n",
    "pd.DataFrame(mpip_obj.sim).to_csv(\"mpip.csv\",sep=\",\",index=False)\n",
    "pred_obj = rating_pred(dataset,test_dataset,mpip = mpip_obj.sim)\n",
    "pred_obj.mp()\n",
    "pd.DataFrame(pred_obj.mpip_pred).to_csv(\"../../results/ml-100k/mpip.csv\")\n",
    "mpip_obj = None\n",
    "pred_obj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_obj = (Cosine(dataset))\n",
    "pd.DataFrame(cosine_obj.sim).to_csv(\"cosine.csv\",sep=\",\",index=False)\n",
    "pred_obj = rating_pred(dataset,test_dataset,cosine = cosine_obj.sim)\n",
    "pred_obj.co()\n",
    "pd.DataFrame(pred_obj.mpip_pred).to_csv(\"../../results/ml-100k/cosine.csv\")\n",
    "cosine_obj = None\n",
    "pred_obj = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_obj = (Jaccard(dataset))\n",
    "pd.DataFrame(jaccard_obj.sim).to_csv(\"jaccard.csv\",sep=\",\",index=False)\n",
    "pred_obj = rating_pred(dataset,test_dataset,jaccard = jaccard_obj.sim)\n",
    "pred_obj.ja()\n",
    "pd.DataFrame(pred_obj.mpip_pred).to_csv(\"../../results/ml-100k/jaccard.csv\")\n",
    "jaccard_obj = None\n",
    "pred_obj = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_obj = (pearson(dataset))\n",
    "pd.DataFrame(pearson_obj.sim).to_csv(\"pearson.csv\",sep=\",\",index=False)\n",
    "pred_obj = rating_pred(dataset,test_dataset,pearson = pearson.sim)\n",
    "pred_obj.pe()\n",
    "pd.DataFrame(pred_obj.mpip_pred).to_csv(\"../../results/ml-100k/pearson.csv\")\n",
    "pearson = None\n",
    "pred_obj = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mpip_Scaled = mpip_obj.sim.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in Mpip_Scaled.columns:\n",
    "    Mpip_Scaled[column] = (Mpip_Scaled[column] - Mpip_Scaled[column].min()) / (Mpip_Scaled[column].max() - Mpip_Scaled[column].min())   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mpip_Scaled = pd.DataFrame(Mpip_Scaled)\n",
    "Mpip_Scaled.to_csv('mpipscaled.csv',sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpip_sim = pd.read_csv('mpipscaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpip_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpip_sim.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpip_sim.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [str(x) for x in range(0,943)]\n",
    "df = pd.DataFrame(columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,943):\n",
    "    a_ = mpip_sim.iloc[:,i]\n",
    "    s = np.array(a_)\n",
    "    sort_index = np.argsort(s)\n",
    "    sort_index = sort_index[0:200]\n",
    "    df.iloc[:,i] = sort_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Top_200_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sparsity reduction using similar users (MPIP) and imputation\n",
    "r_cols = ['user_id','movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('u.data', sep='\\t', names=r_cols)\n",
    "ratings.drop(\"unix_timestamp\", inplace = True, axis = 1)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix = ratings.pivot(index='movie_id',columns='user_id',values='rating')\n",
    "utility_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix = utility_matrix.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,943):\n",
    "    for j in range(0,943):\n",
    "        if (utility_matrix.iloc[i,j]==0):\n",
    "            for k in range (0,100):\n",
    "                us = df.iloc[k,i]\n",
    "                if (utility_matrix.iloc[i,k]==0):\n",
    "                    print(i)\n",
    "                else:\n",
    "                    utility_matrix.iloc[i,j] = utility_matrix.iloc[i,k]\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_matrix.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of empty cells in the matrix (movie_user_matrix2)\n",
    "empty_cells = utility_matrix.isna().sum().sum()\n",
    "empty_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the sparsity of the matrix (movie_user_matrix2)\n",
    "sparsity = empty_cells/utility_matrix.size\n",
    "print(\"The sparsity of the matrix is: \", sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final dataset after sparsity reduction in form of (User, Movie, Rating)\n",
    "# Final dataframe after unpivoting the deter_data matrix\n",
    "final_df = utility_matrix.stack().reset_index()\n",
    "final_df.columns=['movie_id','user_id','rating']\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_titles = [\"user_id\",\"movie_id\",\"ratings\"]\n",
    "final_df=final_df.reindex(columns=columns_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings :\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Handle table-like data and matrices :\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "import itertools\n",
    "\n",
    "# Modelling Helpers :\n",
    "#from sklearn.preprocessing import Imputer , Normalizer , scale\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
    "\n",
    "# Evaluation metrics :\n",
    "# Regression\n",
    "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Classification\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "\n",
    "# Deep Learning Libraries\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "\n",
    "# Configure visualisations\n",
    "%matplotlib inline\n",
    "mpl.style.use( 'ggplot' )\n",
    "plt.style.use('fivethirtyeight')\n",
    "sns.set(context=\"notebook\", palette=\"dark\", style = 'whitegrid' , color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\");\n",
    "\n",
    "\n",
    "# Make Visualizations better\n",
    "params = { \n",
    "    'axes.labelsize': \"large\",\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'legend.fontsize': 20,\n",
    "    'figure.dpi': 150,\n",
    "    'figure.figsize': [25, 7]\n",
    "}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_cols = ['userID', 'movieID', 'ratings','timestamp']\n",
    "r_cols1 = [ 'movieID', 'movie title', 'release date', 'IMDB', 'unknown', 'Action', 'Adventure', 'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western' ]\n",
    "ratings = pd.read_csv('final_dataset.csv', sep='\\t', names=r_cols,\n",
    "                      encoding='latin-1')\n",
    "movies = pd.read_csv('u.item', sep='|', names=r_cols1,\n",
    "                      encoding='latin-1', index_col=3)\n",
    "df_r = ratings.copy()\n",
    "df_m = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['movieID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['timestamp'], axis=1, inplace=True)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape: ', movies.shape, '\\n')\n",
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Input, dot, concatenate\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = ratings.iloc[:,:2]\n",
    "#Y = ratings.iloc[:,2]\n",
    "\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = ratings.groupby('userID')['ratings'].count()\n",
    "top_users = g.sort_values(ascending=False)[:15]\n",
    "g = ratings.groupby('movieID')['ratings'].count()\n",
    "top_movies = g.sort_values(ascending=False)[:15]\n",
    "top_r = ratings.join(top_users, rsuffix='_r', how='inner', on='userID')\n",
    "top_r = top_r.join(top_movies, rsuffix='_r', how='inner', on='movieID')\n",
    "pd.crosstab(top_r.userID, top_r.movieID, top_r.ratings, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "ratings['user'] = user_enc.fit_transform(ratings['userID'].values)\n",
    "n_users = ratings['user'].nunique()\n",
    "item_enc = LabelEncoder()\n",
    "ratings['movie'] = item_enc.fit_transform(ratings['movieID'].values)\n",
    "n_movies = ratings['movie'].nunique()\n",
    "ratings['ratings'] = ratings['ratings'].values.astype(np.float32)\n",
    "min_rating = min(ratings['ratings'])\n",
    "max_rating = max(ratings['ratings'])\n",
    "n_users, n_movies, min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings[['user', 'movie']].values\n",
    "y = ratings['ratings'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=22)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 100\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecommenderV1(n_users, n_movies, n_factors):\n",
    "    user = Input(shape=(1,))\n",
    "    u = Embedding(n_users, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(user)\n",
    "    u = Reshape((n_factors,))(u)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = Embedding(n_movies, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(movie)\n",
    "    m = Reshape((n_factors,))(m)\n",
    "    \n",
    "    x = Dot(axes=1)([u, m])\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderV1(n_users, n_movies, n_factors)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train, batch_size=128, epochs=100,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for performance\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Add, Activation, Lambda\n",
    "class EmbeddingLayer:\n",
    "    def __init__(self, n_items, n_factors):\n",
    "        self.n_items = n_items\n",
    "        self.n_factors = n_factors\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x = Embedding(self.n_items, self.n_factors, embeddings_initializer='he_normal',\n",
    "                      embeddings_regularizer=l2(1e-6))(x)\n",
    "        x = Reshape((self.n_factors,))(x)\n",
    "        return x\n",
    "def RecommenderV2(n_users, n_movies, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    ub = EmbeddingLayer(n_users, 1)(user)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    mb = EmbeddingLayer(n_movies, 1)(movie)\n",
    "    x = Dot(axes=1)([u, m])\n",
    "    x = Add()([x, ub, mb])\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderV2(n_users, n_movies, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train, batch_size=128, epochs=100,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for performance\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate, Dense, Dropout\n",
    "def RecommenderNet(n_users, n_movies, n_factors, min_rating, max_rating):\n",
    "    user = Input(shape=(1,))\n",
    "    u = EmbeddingLayer(n_users, n_factors)(user)\n",
    "    \n",
    "    movie = Input(shape=(1,))\n",
    "    m = EmbeddingLayer(n_movies, n_factors)(movie)\n",
    "    \n",
    "    x = Concatenate()([u, m])\n",
    "    x = Dropout(0.05)(x)\n",
    "    \n",
    "    x = Dense(100, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Dense(1, kernel_initializer='he_normal')(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    x = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(x)\n",
    "    model = Model(inputs=[user, movie], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommenderNet(n_users, n_movies, n_factors, min_rating, max_rating)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=X_train_array, y=y_train, batch_size=128, epochs=100,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for performance\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
